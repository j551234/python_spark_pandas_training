{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc6400a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/10/18 15:16:06 WARN Utils: Your hostname, james-MS-7A69 resolves to a loopback address: 127.0.1.1; using 10.100.0.179 instead (on interface enp0s31f6)\n",
      "21/10/18 15:16:06 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/james/anaconda3/envs/python_practice/lib/python3.9/site-packages/pyspark/jars/spark-unsafe_2.12-3.1.2.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "21/10/18 15:16:07 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------------+\n",
      "|dislikes|           title|\n",
      "+--------+----------------+\n",
      "|    1204|Film & Animation|\n",
      "|     348|Film & Animation|\n",
      "|    2520|Film & Animation|\n",
      "|      84|Film & Animation|\n",
      "|      27|Film & Animation|\n",
      "|     831|Film & Animation|\n",
      "|   60025|Film & Animation|\n",
      "|    1985|Film & Animation|\n",
      "|    3657|Film & Animation|\n",
      "|    5508|Film & Animation|\n",
      "|     648|Film & Animation|\n",
      "|    8506|Film & Animation|\n",
      "|     569|Film & Animation|\n",
      "|     224|Film & Animation|\n",
      "|    8927|Film & Animation|\n",
      "|      60|Film & Animation|\n",
      "|     543|Film & Animation|\n",
      "|     956|Film & Animation|\n",
      "|    1135|Film & Animation|\n",
      "|   51293|Film & Animation|\n",
      "+--------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 7:=====================================================> (195 + 1) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+\n",
      "|               title|   dislikes|\n",
      "+--------------------+-----------+\n",
      "|       Entertainment|2.5791583E7|\n",
      "|               Music| 2.209819E7|\n",
      "|      People & Blogs|  9480796.0|\n",
      "|              Comedy|  5372515.0|\n",
      "|              Sports|  3286369.0|\n",
      "|     News & Politics|  3264041.0|\n",
      "|    Film & Animation|  3111259.0|\n",
      "|              Gaming|  2446882.0|\n",
      "|Science & Technology|  1791153.0|\n",
      "|       Howto & Style|  1730520.0|\n",
      "+--------------------+-----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, substring\n",
    "from pyspark.sql.types import IntegerType\n",
    "import pyspark.sql.functions as f\n",
    "\n",
    "spark = SparkSession.builder.master(\"local[1]\") \\\n",
    "                    .appName('py_spark') \\\n",
    "                    .getOrCreate()\n",
    "\n",
    "\n",
    "csvDF =spark.read.option(\"header\",True).csv(\"/home/james/python_practice/archive/CAvideos.csv\")\n",
    "\n",
    "jsonDF =spark.read.option(\"multiLine\", True).json(\"/home/james/python_practice/archive/CA_category_id.json\").rdd.flatMap(lambda x:x[\"items\"]).toDF()\n",
    "\n",
    "joinDF=csvDF.join(jsonDF, csvDF['category_id'] == jsonDF['id'] )\n",
    "\n",
    "cast_df =joinDF.withColumn(\"dislikes\",  col('dislikes').cast(IntegerType()))\n",
    "cast_df=joinDF.select(joinDF[\"dislikes\"],joinDF['snippet.title'])\n",
    "cast_df.show()\n",
    "final_df =cast_df.groupBy('title').agg(f.sum('dislikes').alias('dislikes')).sort(f.col('dislikes').desc()).head(10)\n",
    "spark.createDataFrame(final_df).show()\n",
    "# joinDF.show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a221267",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d59869aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+\n",
      "|               title|dislikes|\n",
      "+--------------------+--------+\n",
      "|WE ARE ALL GOING ...|    3035|\n",
      "|WE ARE ALL GOING ...|    3322|\n",
      "|WE ARE ALL GOING ...|    3473|\n",
      "|STUNG by a WARRIO...|    1486|\n",
      "|STUNG by a WARRIO...|    2433|\n",
      "|STUNG by a WARRIO...|    2754|\n",
      "|STUNG by a WARRIO...|    2932|\n",
      "|STUNG by a WARRIO...|    3042|\n",
      "|Dog Cries Every T...|    1224|\n",
      "|Heart-Wrenching V...|    1455|\n",
      "|BITTEN by a GIANT...|    1646|\n",
      "|BITTEN by a GIANT...|    2354|\n",
      "|VENOM EXTRACTION ...|    1701|\n",
      "|VENOM EXTRACTION ...|    2391|\n",
      "|VENOM EXTRACTION ...|    2745|\n",
      "|VENOM EXTRACTION ...|    2981|\n",
      "|VENOM EXTRACTION ...|    3182|\n",
      "|The Smallest Bird...|    1015|\n",
      "|The Smallest Bird...|    1581|\n",
      "|The Smallest Bird...|    1827|\n",
      "+--------------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bigger_df=joinDF[joinDF['dislikes'] >1000]\n",
    "bigger_df = bigger_df['title','dislikes']\n",
    "bigger_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4baac32c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
